{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693086a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx_tf\n",
      "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
      "     |████████████████████████████████| 226 kB 6.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.9/site-packages (from onnx_tf) (0.14.0)\n",
      "Collecting onnx>=1.10.2\n",
      "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "     |████████████████████████████████| 13.5 MB 109.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from onnx_tf) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.9/site-packages (from onnx>=1.10.2->onnx_tf) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from onnx>=1.10.2->onnx_tf) (1.21.4)\n",
      "Collecting protobuf<4,>=3.20.2\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "     |████████████████████████████████| 1.0 MB 67.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.9/site-packages (from tensorflow-addons->onnx_tf) (2.13.2)\n",
      "Installing collected packages: protobuf, onnx, onnx-tf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed onnx-1.13.1 onnx-tf-1.10.0 protobuf-3.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c80009f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /opt/conda/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.9/site-packages (from onnx) (4.0.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /opt/conda/lib/python3.9/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from onnx) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5961f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "     |████████████████████████████████| 6.7 MB 3.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (2.0.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (0.12.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow-probability) (1.21.4)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "     |████████████████████████████████| 153 kB 102.7 MB/s            \n",
      "\u001b[?25hInstalling collected packages: dm-tree, tensorflow-probability\n",
      "Successfully installed dm-tree-0.1.8 tensorflow-probability-0.19.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc46abbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.12.0\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "     |████████████████████████████████| 585.9 MB 8.1 kB/s              \n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 85.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (3.20.3)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     |████████████████████████████████| 17.1 MB 88.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (1.42.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     |████████████████████████████████| 2.4 MB 62.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (59.4.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     |████████████████████████████████| 126 kB 78.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (21.3)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     |████████████████████████████████| 440 kB 56.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (4.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (3.1.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "     |████████████████████████████████| 22.9 MB 63.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (1.1.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 48.9 MB/s            \n",
      "\u001b[?25hCollecting jax>=0.3.15\n",
      "  Downloading jax-0.4.6.tar.gz (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 80.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (1.6.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.12.0) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.37.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.2)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     |████████████████████████████████| 4.8 MB 73.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.6)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 89.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow==2.12.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.10)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "     |████████████████████████████████| 16.8 MB 73.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.1)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.6-py3-none-any.whl size=1432730 sha256=96d76188ed534a0d221167f64bd0193d9f9e0c58fad48e953487d5af076c092c\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/68/2c/93/17deec4d117dc0675ed79e8e2af1e62fb1c41ed3955c540de0\n",
      "Successfully built jax\n",
      "Installing collected packages: numpy, tensorboard-data-server, grpcio, absl-py, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, jax, flatbuffers, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.7.0\n",
      "    Uninstalling tensorboard-2.7.0:\n",
      "      Successfully uninstalled tensorboard-2.7.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 1.4.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.4.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 23.3.3 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.4 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.4.0 flatbuffers-23.3.3 grpcio-1.51.3 jax-0.4.6 keras-2.12.0 libclang-16.0.0 numpy-1.22.4 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "--2023-03-26 15:54:59--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5188 (5.1K) [text/plain]\n",
      "Saving to: ‘/opt/conda/lib/python3.9/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/opt/conda/lib/pyth 100%[===================>]   5.07K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-03-26 15:54:59 (52.6 MB/s) - ‘/opt/conda/lib/python3.9/site-packages/google/protobuf/internal/builder.py’ saved [5188/5188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dependency 문제 해결책\n",
    "!pip install tensorflow==2.12.0\n",
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /opt/conda/lib/python3.9/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8dda8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_tf\n",
    "import torch\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2213b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bac9b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/a_project/viton/fashionpedia_tf_ckp/fashionpedia-r50-fpn'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.ckpt이름으로 부르면 된다.\n",
    "# tf_model_path= \"aiffel/aiffel/a_project/viton/fashionpedia_tf_ckp/fashionpedia-r50-fpn\"\n",
    "tf_model_path=\"/aiffel/aiffel/a_project/viton/fashionpedia_tf_ckp/fashionpedia-r50-fpn/model.ckpt\"\n",
    "tf_model_dir=os.path.dirname(tf_model_path)\n",
    "tf_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5133ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  model.ckpt.data-00000-of-00001  model.ckpt.index  model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls {tf_model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_model = tf.keras.models.load_model(tf_model_path)\n",
    "# tf_model= tf.keras.models.load_model(tf_model_dir)\n",
    "\n",
    "# mask r-cnn을 찾아야 한다.\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dfb5540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1782988728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# tf.keras.saving.load_weights(\"fashionpedia-r50-fpn\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# tf.train.Checkpoint(model=tf_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fashionpedia-r50-fpn/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model=tf.keras.models.load_model(tf_model_path)\n",
    "# tf.keras.saving.load_model(\"fashionpedia-r50-fpn/model.ckpt\")\n",
    "# tf.keras.saving.load_model(\"fashionpedia-r50-fpn\")\n",
    "# tf.keras.saving.load_weights(\"fashionpedia-r50-fpn/model.ckpt\")\n",
    "# tf.keras.saving.load_weights(\"fashionpedia-r50-fpn\")\n",
    "# tf.train.Checkpoint(model=tf_model)\n",
    "\n",
    "# 확실해진 한가지: 모델을 직접 만든 다음 넣어줘야 한다.\n",
    "# 위의 코드들은 제대로 파일을 잡아내지 못해서 뜨는 오류만 떴지만(쳇지피티 썅놈... )\n",
    "# 아래 코드는 모델을 만든 다음 실행시켰을 때 돌아가다가 \n",
    "# Some objects had attributes which were not restored라고 뜨는 것을 확인함(이 코드에는 모델이 없으니 구축을 하긴 해야됨)\n",
    "#model.load_weights(\"fashionpedia-r50-fpn/model.ckpt\")\n",
    "\n",
    "# 결론 mask-rcnn중 resnet 50 fpn필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7974858e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.applications' has no attribute 'ResNet50FPN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resnet_fpn \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50FPN\u001b[49m(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model.load_weights(tf_model_path)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.applications' has no attribute 'ResNet50FPN'"
     ]
    }
   ],
   "source": [
    "resnet_fpn = tf.keras.applications.ResNet50FPN(weights='imagenet', include_top=False)\n",
    "# model.load_weights(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41ff42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6228320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963630fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43cad02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46670d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_341/2142121733.py\", line 10, in <module>\n      model.fit(train_images,\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_2'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_2}}]] [Op:__inference_train_function_758]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path,\n\u001b[1;32m      6\u001b[0m                                                  save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                                                  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model with the new callback\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass callback to training\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# This may generate warnings related to saving the state of the optimizer.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# These warnings (and similar warnings throughout this notebook)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# are in place to discourage outdated usage, and can be ignored.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_341/2142121733.py\", line 10, in <module>\n      model.fit(train_images,\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_2'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_2}}]] [Op:__inference_train_function_758]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee9fa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/a_project/viton/fashionpedia_tf_ckp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba30fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
